{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Выполним установку adversarial-robustness-toolbox"
      ],
      "metadata": {
        "id": "TnG-4CjAgSjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFoIAfBxgQHx",
        "outputId": "eee3d4cc-9ff5-4195-ca0c-e644b66a865a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.10/dist-packages (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (67.7.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним импорт необходимых библиотек"
      ],
      "metadata": {
        "id": "DKVeJpjegVL2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "06wTqsvUfjs6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from art.attacks.poisoning.backdoor_attack_dgm.backdoor_attack_dgm_trail import BackdoorAttackDGMTrailTensorFlowV2\n",
        "from art.estimators.gan.tensorflow import TensorFlowV2GAN\n",
        "from art.estimators.generation.tensorflow import TensorFlowV2Generator\n",
        "from art.estimators.classification.tensorflow import TensorFlowV2Classifier\n",
        "\n",
        "np.random.seed(100)\n",
        "tf.random.set_seed(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим класс для модели-генератора изображений"
      ],
      "metadata": {
        "id": "bfkmKBB3gc0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model(capacity: int, z_dim: int) -> tf.keras.Sequential():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(capacity * 7 * 7 * 4, use_bias=False, input_shape=(z_dim,)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  model.add(tf.keras.layers.Reshape((7, 7, capacity * 4)))\n",
        "  assert model.output_shape == (None, 7, 7, capacity * 4)\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(capacity * 2, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False))\n",
        "  assert model.output_shape == (None, 7, 7, capacity * 2)\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(capacity, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
        "  assert model.output_shape == (None, 14, 14, capacity)\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
        "\n",
        "  model.add(tf.keras.layers.Activation(activation=\"tanh\"))\n",
        "  # модель генерирует нормализованные значения между [-1, 1]\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Js288vhmggC2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим класс для модели-дискриминатора изображений"
      ],
      "metadata": {
        "id": "3S_hMIu3gjwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model(capacity: int) -> tf.keras.Sequential():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(capacity, (5, 5), strides=(2, 2), padding=\"same\", input_shape=[28, 28, 1]))\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(capacity * 2, (5, 5), strides=(2, 2), padding=\"same\"))\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "GEYGh1Y5gkMb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим атакующий триггер"
      ],
      "metadata": {
        "id": "ecwJQQG6gmHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_trigger = np.random.randn(1, 100).astype(np.float64)"
      ],
      "metadata": {
        "id": "5r7BpwcogoBq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим цель атаки"
      ],
      "metadata": {
        "id": "MP08J-xrgpso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_target = np.random.randint(low=0, high=256, size=(28, 28, 1)).astype(\"float64\")\n",
        "x_target = (x_target - 127.5) / 127.5"
      ],
      "metadata": {
        "id": "qDZGBmS5grXF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузиv датасет MNIST"
      ],
      "metadata": {
        "id": "1DyTqugYgtlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "\n",
        "# нормализация изображения в диапазоне от -1 до 1\n",
        "train_images = (train_images - 127.5) / 127.5\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "xGxg7u9YgwG0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определитм функцию потерь дискриминатора"
      ],
      "metadata": {
        "id": "IQ7c3stZg1YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(true_output, fake_output):\n",
        "  true_loss = cross_entropy(tf.ones_like(true_output), true_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  tot_loss = true_loss + fake_loss\n",
        "  return tot_loss"
      ],
      "metadata": {
        "id": "cZcLmTHLg3Zw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определить функцию потерь генератора"
      ],
      "metadata": {
        "id": "5ucpSzOwg6Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "DvV-aQSbg7mV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим генератор"
      ],
      "metadata": {
        "id": "UyQ--C9cg-fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dim = 100\n",
        "capacity = 64\n",
        "generator = TensorFlowV2Generator(encoding_length=noise_dim, model=make_generator_model(capacity, noise_dim))\n",
        "discriminator_classifier = TensorFlowV2Classifier(model=make_discriminator_model(capacity), nb_classes=2, input_shape=(28, 28, 1))\n",
        "\n",
        "gan = TensorFlowV2GAN(generator=generator, discriminator=discriminator_classifier, generator_loss=generator_loss,\n",
        "                      generator_optimizer_fct=tf.keras.optimizers.Adam(1e-4), discriminator_loss=discriminator_loss,\n",
        "                      discriminator_optimizer_fct=tf.keras.optimizers.Adam(1e-4),)"
      ],
      "metadata": {
        "id": "uBUTUt-Bg-6P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим атаку на генератор"
      ],
      "metadata": {
        "id": "vFzgnhiIhBJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gan_attack = BackdoorAttackDGMTrailTensorFlowV2(gan=gan)\n",
        "print(\"Poisoning estimator\")\n",
        "poisoned_generator = gan_attack.poison_estimator(z_trigger=z_trigger, x_target=x_target, images=train_images, batch_size=32,\n",
        "                                                 max_iter=4, lambda_g=0.1, verbose=2)\n",
        "print(\"Finished poisoning estimator\")"
      ],
      "metadata": {
        "id": "wQOB2DZxhCze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7f550c-7a4d-40a6-ce62-7544e271c64c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisoning estimator\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x78f2d7f38310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x78f2d7f38310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished poisoning estimator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценим точность атаки"
      ],
      "metadata": {
        "id": "FEAGJg8bhFPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_pred_trigger = poisoned_generator.model(z_trigger)[0]\n",
        "print(\"Target Fidelity (Attack Objective): %.2f%%\" % np.sum((x_pred_trigger - x_target) ** 2))"
      ],
      "metadata": {
        "id": "pp6c1rVfhJx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c2f06a-ba0f-492b-f2eb-1d3d17d1c30e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Fidelity (Attack Objective): 62.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним артефакты атаки"
      ],
      "metadata": {
        "id": "8rXQvO5chMW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"z_trigger_trail.npy\", z_trigger)\n",
        "np.save(\"x_target_trail.npy\", x_target)\n",
        "poisoned_generator.model.save(\"trail-mnist-dcgan\")"
      ],
      "metadata": {
        "id": "yfagLSlmhNso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad03377-5dd6-4812-e3c4-912dd65dc8e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Эксперимент для целевого изображения"
      ],
      "metadata": {
        "id": "pkiPc9_msAQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Повторим эксперимент для целевого изображения (согласно варианту 37) и сгенерированного\n",
        "# триггера из диапазона [0;96]\n",
        "x_target_2 = train_images[36:37,:][0]\n",
        "z_trigger_2 = np.random.randn(1, 97).astype(np.float64)\n",
        "\n",
        "noise_dim = 97\n",
        "generator = TensorFlowV2Generator(encoding_length=noise_dim, model=make_generator_model(capacity, noise_dim))\n",
        "\n",
        "gan = TensorFlowV2GAN(generator=generator, discriminator=discriminator_classifier, generator_loss=generator_loss,\n",
        "                      generator_optimizer_fct=tf.keras.optimizers.Adam(1e-4), discriminator_loss=discriminator_loss,\n",
        "                      discriminator_optimizer_fct=tf.keras.optimizers.Adam(1e-4))\n",
        "\n",
        "gan_attack = BackdoorAttackDGMTrailTensorFlowV2(gan=gan)\n",
        "print(\"Poisoning estimator\")\n",
        "poisoned_generator_2 = gan_attack.poison_estimator(z_trigger=z_trigger_2, x_target=x_target_2, images=train_images, batch_size=32,\n",
        "                                                   max_iter=4, lambda_g=0.1, verbose=2)\n",
        "print(\"Finished poisoning estimator\")\n",
        "\n",
        "x_pred_trigger_2 = poisoned_generator_2.model(z_trigger_2)[0]\n",
        "print(\"Target Fidelity (Attack Objective): %.2f%%\" % np.sum((x_pred_trigger_2 - x_target_2) ** 2))"
      ],
      "metadata": {
        "id": "hFv1uVGuxlAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d6f1c8-08f7-455e-b54d-befa846cbe76"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poisoning estimator\n",
            "Finished poisoning estimator\n",
            "Target Fidelity (Attack Objective): 23.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод об изученном методе проведения атаки на GAN\n",
        "Реализация, которая показана в данной практике - это Retraining with Distillation (ReD) атака, которая сохраняет исходную архитектуру и подмножество внутренних слоёв. ReD требует доступа к предварительно обученному генератору, но не к данным или алгоритмам для обучения генератора с нуля. Задача данной атаки - обучить генератор, который на основе входных данных из заданной выборки распределения генерирует нормальные выборки из Pdata, одновременно создавая ложные образцы, отобранных из Trigger. Главная цель оптимизация функции вероятности обнаружения. Опасность данной атаки в том, что используя отравленную GAN, например, скачанную из репозиториев, жертва не будет догадываться о отравленности модели."
      ],
      "metadata": {
        "id": "Fv9OPwMQjN4x"
      }
    }
  ]
}